{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fd9e92e",
   "metadata": {},
   "source": [
    "Purpose of this notebook:\n",
    "\n",
    "-Imports and runs the entire run_rag_pipeline(...) function\n",
    "-Toggle force_rebuild\n",
    "-Checks if cache exists\n",
    "-Sends a user query and prints the LLaMA3 response\n",
    "\n",
    "Meant for designed for testing the whole RAG system end-to-end quickly and is perfect for:\n",
    "-Presenting and Checking if everything is working together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64874358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0 — Fix sys.path so we can import modules from app/\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Path: rag_pipeline_project/app/notebooks/\n",
    "# We want to reach: rag_pipeline_project/\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c49d7142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports from your RAG app\n",
    "from app.rag_pipeline import run_rag_pipeline\n",
    "from app.utils import clear_cache, is_chroma_cache_present"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7220dfb5",
   "metadata": {},
   "source": [
    "## Optionally Clear the Cache\n",
    "\n",
    "Use `clear_cache()` if:\n",
    "- You added or changed PDFs\n",
    "- You want to rebuild vector DB from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75978aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment to delete the embeddings/chromadb folder\n",
    "#clear_cache()\n",
    "\n",
    "# Check if cached embeddings already exist\n",
    "is_chroma_cache_present()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823ba9e3",
   "metadata": {},
   "source": [
    "## User Question (based on TikTok misinformation)\n",
    "\n",
    "Set the user’s query. Example:\n",
    "> \"I saw a TikTok saying Germany wants to ban all immigration. Is that true?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43124bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I saw a TikTok saying that CDU wants to ban all immigration. Is that true?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f3ff09",
   "metadata": {},
   "source": [
    "## Run the RAG pipeline\n",
    "\n",
    "This step:\n",
    "1. Uses your motivational interviewing system prompt\n",
    "2. Loads cached ChromaDB if available\n",
    "3. Rebuilds only if forced or missing\n",
    "4. Sends everything to LLaMA3 via Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "207f9a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached ChromaDB index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/crl/Desktop/Langchain-rag-practical/rag_pipeline_project/app/rag_pipeline.py:48: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embedding_function=OllamaEmbeddings(model=EMBED_MODEL),\n",
      "/home/crl/Desktop/Langchain-rag-practical/rag_pipeline_project/app/rag_pipeline.py:46: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n",
      "/home/crl/Desktop/Langchain-rag-practical/rag_pipeline_project/app/rag_pipeline.py:70: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  relevant_docs = retriever.get_relevant_documents(user_query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Retrieved chunks ---\n",
      "Let's explore this together. I'm here to help you make sense of the information you've come across.\n",
      "\n",
      "## Understanding Your Concerns\n",
      "\n",
      "Can you tell me more about what you saw on TikTok? What specifically caught your attention, and how did it make you feel?\n"
     ]
    }
   ],
   "source": [
    "# Set force_rebuild to True if PDFs changed or cache is broken\n",
    "force = False\n",
    "\n",
    "response = run_rag_pipeline(query, force_rebuild=force)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
